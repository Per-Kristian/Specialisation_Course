\newcommand{\comment}[1]{}

%\documentclass[a4paper,twocolumn,12pt]{article}

%\documentclass[a4wide,12pt]{report}

%\documentclass[a4wide,12pt]{article}
%\documentclass[informasjonssikkerhet]{gucmasterproject}
%\documentclass[informationsecurity]{gucmasterproject}
\documentclass[informationsecurity]{gucmasterproject}

%\usepackage{pslatex} %% Doesn't seem to work - i.e. convert .eps to .pdf
 
\usepackage[utf8]{inputenc}     % For utf8 encoded .tex files
%\usepackage[latin1]{inputenc}
\usepackage[british]{babel}     % For chapter headings etc.
%\usepackage[pdftex]{graphicx}           % For inclusion of graphics

%From http://math.uib.no/it/tips/
   %% For grafikk
    \usepackage{ifpdf}
    \ifpdf
      \usepackage[pdftex]{graphicx}
      \usepackage{epstopdf}
    \else
      \usepackage[dvips]{graphicx}
    \fi
    %% Her kan du putte dine vanlige pakker og definisjoner



%\usepackage[dvips]{hyperref}    % For cross references in pdf
\usepackage{hyperref}
\usepackage{mdwlist}
\usepackage{url}
\usepackage{here}

\def\UrlFont{\tt}

\begin{document}

\thesistitle{A survey of periodic authentication systems based on keyboard dynamics}
\thesisauthor{Per-Kristian Nilsen}
\thesisdate{\gucmasterthesisdate}
\useyear{2017}
\makefrontpages % make the frontpages
%\thesistitlepage % make the ordinary titlepage


\comment{
Front page - including
"   NTNU technical report front page including logos etc.
"   The text: "Specialization Report"
"   Title of project
"   Name of author and contact details
"   Date
"   Version

email address
"   MIS students must include "NISlab" as their affiliation.
Date:22.10.2003

Structure of Specialization Report
NTNU in Gj\o{}ovik
}



\begin{abstract}


\end{abstract}


\tableofcontents

\chapter{Introduction}
Biometrics is increasingly utilized for user authentication, with fingerprint readers being built into personal devices such as smart phones and laptops.
Biometric systems based on modalities such as fingerprint, hand print, iris, retina and facial recognition are to varying degrees now known to the general public.
A common feature of these modalities are that they are \textit{physiological} -- they are based on our individual anatomy.
On the other hand, \textit{behavioral} biometric systems are not yet as widely used as its physiological counterpart, largely due to lesser reliability and being more prone to changes over time.

Behavioral biometrics are, as the name implies, based on the behavior of an individual. Behavioral modalities include (but are not limited to) gait recognition, voice recognition, mouse dynamics and keyboard dynamics, with the latter being the focus of this literature study.
'Keyboard dynamics' is a term revolving around capturing the features from a person's typing rhythm, and using them for purposes such as user authentication, identification and classification.
\textit{Identification} means determining whether or not a person is a known user of a system, and if so, who it is.
\textit{Classification} is the process of determining who a person is within a set of possible individuals, while \textit{authentication} is verifying whether or not a person is who they claim to be.

These systems may be used either to \textit{grant access} or to \textit{revoke access}.
Similar to password based authentication, keystroke dynamics can be utilized for initial \textit{static (one-time) authentication}, granting a legal user access to their system.
One approach to this kind of authentication is having a user write a predetermined and fixed sample text of which typing features are extracted to form a probe template to be compared to their previously enrolled reference template.
The text may be short or long, depending on the authentication system at hand.  
An example of a short text may the user's password, while long text could be a short news article.

\textit{Dynamic authentication} generally takes place after static authentication, and revokes system access if the result is negative.
The user is repeatedly authenticated throughout their session, as an additional layer of security on top of the static authentication.
Again, both fixed- and free-text can be used for this purpose.
There are two approaches to free-text dynamic authentication, namely \textit{continuous} and \textit{periodic} authentication, both of which rely on passively monitoring the user's typing behavior, and determining whether the current user is the genuine user of the logged-in account.
Periodic authentication (PA) systems rely on passively recording a \textit{block} sample of keystrokes of which features are extracted from to generate a probe template when the block is filled.
These features are then compared to the reference template, similarly to the static authentication systems previously mentioned.
The authors of PA systems have a tendency of calling their methods "continuous authentication" (CA), but as Bours pointed out in his paper proposing a true CA system, the term "continuous" implies that the authentication process is performed after each individual keystroke \cite{BOURS201236}.
I will therefore refer to all PA systems in the literature as "periodic", regardless if the authors themselves refer to their methods as "continuous".

CA systems such as the one proposed in \cite{BOURS201236} only considers the last keystroke plus its relation to the keystroke before (if any).
Similarly to PA systems, these features are then compared to the reference template, however, CA systems have much less statistics to work with compared to PA systems.
The upside to CA systems is that they react instantly to every user action, such as increasing or lowering the trust in the user's genuineness in Bours' system \cite{BOURS201236}.
On the contrary, PA systems cannot react to impostors until enough keystrokes have occured to fill the block.
Until that happens, the impostor has free reign over the genuine user's account in the system.

The features extracted from keystrokes vary between different systems.
For single key actions, there are two events happening, namely Key Down and Key Up, which means pressing and releasing the key, respectively.
Timestamps are associated with these events, usually in the form of milliseconds.
From these timestamps, the \textit{duration/dwell time} of the keypress can easily be determined.
When two or more sequential keypresses (n-graphs) are to be considered in relation to each other, a number of features can be extracted.
As an example, the \textit{digraph} 'AB' may have the timing values as shown in \autoref{tab:timing-example}.
From those values, one could extract the durations of the single keys, but also the following features: 

\begin{itemize}
\item A\textsubscript{down}--B\textsubscript{down} (latency)
\item (A\textsubscript{down}--B\textsubscript{up}) (duration)
\item (A\textsubscript{up}--B\textsubscript{down}) (flight time)
\item (A\textsubscript{up}--B\textsubscript{up}) (latency)
\end{itemize}
The respective latency values would then be 45, 60, 25 and 40 milliseconds, calculated by subtracting the timestamp of the first key from the timestamp of the second key.
The authentication system could then use these features to calculate the similarity to the reference template for instance by using one or more distance measures, or by using machine learning algorithms.

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
         \bf Key & \bf Action & \bf Timestamp (ms)\\
         A & Down & 80\\
         A & Up & 100\\
         B & Down & 125\\
         B & Up & 140
    \end{tabular}
    \caption{Example timing values for 'AB' digraph.}
    \label{tab:timing-example}
\end{table}

Another difference between PA and CA systems in literature is the way performance is reported.
False Accept Rate (FAR), False Reject Rate (FRR) and Equal Error Rate(EER) are generally used for indicating the performance of PA classification algorithms.
FAR represents the percentage of imposters being falsely accepted, which indicates the security level of the system. 
FRR represents the percentage of genuine users being falsely rejected, which has implications for user acceptance, as being rejected too often would be a source of irritation.
These two rates are inversely proportional to each other, as lowering the FAR inherently increases the FRR.
The ERR therefore shows the point where the FAR and FRR of a system have the same value.
These rates must be looked at in relation to the PA system's block size in order to be meaningful.
I would also like to mention that much of the PA literature misuses the FAR and FRR terms, as they are system-level evaluation metrics, and they are often wrongly used to describe the performance of their classification algorithms.
According to the vocabulary specified in the ISO/IEC 2382-37 standard \cite{ISO-voc}, the correct terms for algorithm level performance is False Match Rate (FMR) and False Non-Match Rate (FNMR), and I will replace wrongly used terms where applicable when discussing the literature.

Bours and Mondal proposed in 2015 two new metric for evaluating the performance of CA systems, namely Average Number of Imposter Actions (ANIA) and Average Number of Genuine Actions (ANGA) \cite{CA-performance}.
These rates look at how many actions imposters and genuine users on average can perform before being rejected by the authentication system, as it often is more useful to know how often users will be locked out than the probability of that happening per sample.
They also provide formulas for converting PA systems' FAR into ANIA rates and FRR into ANGA rates.

This purpose of this literature review is to prepare for my upcoming master thesis on combining CA and PA systems.
I will be extending the CA system proposed in Soumik Mondal's PhD thesis \cite{mondal} with a PA system in order to determine if the combination of such systems can have positive effects on performance.
The performance metrics used in said CA system is ANIA and ANGA, and I will therefore use the conversion formulas from \cite{CA-performance} in order to easily compare the performance of PA systems to the CA system's performance.

%NOTE: write more about purpose of this document.
%NOTE: Include description of sections.



%\chapter{Project description evaluation criteria}

%\chapter{Enrollment}
%The enrollment phase of the different papers written on periodic authentication have varying approaches to collecting data for generating reference templates.
%This chapter will cover the approaches most relevant to my master thesis and contain a discussion on which of them, if any, are applicable.
%
%After gathering participants, their keystroke data must be recorded.
%In my case, this phase will last a longer period of time, as the data will be recorded in a completely uncontrolled environment.
%Specifically, the participants will be installing software on their private computers, and the software will record all keyboard activity for as long as the enrollment phase lasts.

%\chapter{Feature extraction}
%While the CA system will consider timing data for monographs, the PA system will likely have focus on digraphs, or possibly n-graphs of greater length.


\chapter{State of the art}
This chapter will contain a summary of the state of the art, with a similar format to that in Mondal's PhD thesis.
The following chapters are discussions of individual PA systems.
Should I have a chapter explaining Mondal's CA system?
\\\\\\\\
%NOTE: Write about what systems use which n-graphs
%NOTE: Remove following text.
Following is a (very) temporary version of what the state of the art overview table may look like.
This will be gradually extended as I write about more papers.
This is mostly just to show what types of information is to be included in the final version.
\begin{table}[h]
\begin{tabular}{ |c|c|c|c|p{1.5cm}|p{1.9cm}|p{2cm}|c| } 
 \hline
 \bf Paper & \bf Block & \bf Users & \bf Uncontr. & \bf Method & \bf Perf. & \bf Notes & n-graphs\\ \hline
 \bf Messerman & 50 - 150 & 55 & Webmail & R\&A &  FAR 2.02\% FRR 1.84\% & adaptive user model & \\ \hline
 \bf Ferreira & 250 & 60 & Yes & R\&A & EER 1.4\% & Updates user profile, also triggers authentication asynch & \\ \hline
 Davoudi(2) & & & & & & & \\ \hline
 %Singh &- & - & - & - & - & STATIC AUTHENT. DONT BOTHER & \\ \hline
 Kaneko & ~200 & 51 & No & Euclidian & 0.66\% EER & Static fixed text, jap. & di \\ \hline
 Ahmed & 500 & 53 & Yes & Neural Networks & FAR 0.0152\% FRR 4.82\% ERR 2.45\% & & mono di\\\hline
 Gunetti & 800 & 40 & Webform & R\&A & FAR 0.005\% FRR 4.833\% & & 2,3,4\\ \hline
 \bf Hu et al. & 36 & 19 & Webform & R\&A, k-NN & FAR 0.045\% FRR 0.005\% & Static text & - \\ \hline
 
\end{tabular}
\end{table}


\chapter{Gunetti \& Picardi}
\label{chap:gnp}
An interesting method for authenticating users was proposed by Gunetti \& Picardi in 2005 in a paper which became highly cited due to its promising results \cite{gnp}.
Their system uses two distance measures, namely absolute (A) and relative (R) measures between samples.
The R and A measures are summed to produce a final distance.
Following is a summary of how the R and A measures are calculated.

With two different text samples, each being an array of shared n-graphs ordered by the n-graphs' typing duration (for instance the time between pressing the first key and the second key), the relative distance between them can be calculated as follows.
The position of each n-graph in one sample is compared to the position of the same n-graph in the other sample, producing a position distance for every n-graph.
The position distances between all the n-graphs are then summed before being normalized, resulting in an R measure.
Normalization is performed by dividing the summed differences by the maximum disorder possible in an array with length equal to the number of shared n-graphs.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{gunetti/R-measure}
    \caption{Computation of relative distance of samples with shared digraphs (a) and trigraphs (b). The figure is borrowed from the original paper \cite{gnp}. All rights to the figure belongs to the authors and/or publisher of said paper.}
    \label{fig:R-measure}
\end{figure}

\autoref{fig:R-measure} demonstrates the comparison between samples.
E1 and E2 are samples of the words \textit{authentication} and \textit{theoretical}, which share the digraphs shown in (a) and trigraphs shown in (b).
As pointed out by the authors, the summed position distances in (a) is $2+0+2+3+1=8$.
As there are five shared digraphs, the maximum disorder of the array is $(5^2-1)/2=12$.
Therefore, the R distance between E1 and E2 in (a) is $8/12 = 0.666$.

A method for combining relative distances based on more than one n-graph is also provided, where the relative distances of the different n-graphs are weighed based on the number of shared n-graps they contain. 
In the example above, (a) and (b) would be combined by summation with weights 5 and 3, respectively.
The reason for these weights is that a distance becomes more meaningful as the number of n-grams it is based on increases, and (a) is in this case the more meaningful case.

The authors state that the purpose of the R measure is to account for differences in typing speed that affect all n-graphs similarly.
They explain this with the example of someone with a headache possibly typing slower, but doing so for all text they input.
It is worth mentioning that this could also be the case if the subject has cold fingers, is under the influence of alcohol or other substances, or a number of other factors.
While everything is typed slower, the \textit{relative} speed between different n-grams in the same sample is likely to be similar to the relative speed between n-grams in another sample where they were typing at normal speed.

On the other hand, the A measure takes the absolute speed of corresponding n-graphs in two samples into account, as the absolute speed of an imposter's typing pattern is less likely to be similar to the reference than that of the genuine user.
For this measure to be calculated, identical n-graphs in two different samples are compared and deemed to either be \textit{similar} or not.
If the durations for these n-graphs are different from eachother, they are regarded as \textit{similar} if the longer duration divided by the shorter duration is between 1 and an arbitrary threshold.
Their reason for using a threshold instead of relying on standard deviation is that it enables them to use n-graphs which only occur once in the samples.
The authors chose 1.25 as the threshold for their experiments after testing various thresholds on the data of the five first subjects in their experiment, to avoid overfitting.
Then, they define the A measure of two samples as 1 -- (number of similar n-graphs between the samples) / (total number of n-graphs shared between the samples).

For example, for the (b) case in \autoref{fig:R-measure}, we can calculate the A measure with a threshold of 1.25 as seen in \autoref{tab:gnp-similar}.
The only similar trigraph pair is 'ica', which means that the A measure for E1 and E2 is $1-(1/3)=0.66$.
In a case where the threshold was set to 1.35, both the 'ica' and 'the' pairs would be regarded as similar, resulting in an A distance measure of $1-(2/3)=0.33$.
\begin{table}[h]
\centering
\begin{tabular}{ccccc}
 \bf Trigraph & \bf E1 & \bf E2 & \bf Calculation &  \\
 tic & 370 & 540 & $540/370=1.46$ &  \\
 ica & 430 & 420 & $430/420=1.02$ & (similar) \\
 the & 450 & 340 & $450/340=1.32$ & 
\end{tabular}
\caption{Similarities between trigraphs from \autoref{fig:R-measure}.}
\label{tab:gnp-similar}
\end{table}

\section{Experimental setting}
For their experiment, they had 40 volunteers submitting 15 samples each, consisting of text written in a webform. On average, the sample length was around 800 characters.
This data was used to build user profiles. 
Another 165 volunteers were asked to provide only one sample each, which was to be used as impostor samples for attacking the genuine user profiles.
The users were asked to only submit one sample per day, though they were free to wait longer between each sample.
The samples were generally collected from the volunteers' workstations and notebooks, and were all written as free-text.

\subsection{Algorithm}
\label{sec:gnp-algorithm}
Suppose a user is claiming the identity of a specific user A (by being logged into A's account) produces a sample X with a certain \textit{mean distance} to every sample in A's profile, denoted by md(A,X).
For X to be recognized as a genuine sample from user A, both of the following requirements must hold \cite{gnp}:

\begin{enumerate}
\item md(A,X) is the smallest with respect to any other md(B,X), where B is another legal user of the system.
\item md(A,X) is smaller than the mean distance between all samples in A's profile m(A), \textbf{or} md(A,X) is closer to m(A) than to any other md(B,X).
\end{enumerate}

\subsection{Performance}
The best performance of their system was achieved using a summation of R and A distances for 2-, 3-, and 4-graphs, reaching an FMR of 0.005\% and an FNMR of 4.833\%, though they call the rates "Imposter Pass Rate (IPR)" and "False Alarm Rate (FAR)".
By using the formula provided in \cite{CA-performance}, we can convert these rates to ANIA and ANGA rates:

\begin{equation}
ANIA = \frac{block size}{(1-FMR)} = \frac{800}{(1-0.00005)} \approx 800
\end{equation}

\begin{equation}
ANGA = \frac{block size}{FNMR} = \frac{800}{0.04833} \approx 16553 
\end{equation}
The ANGA rate of 16553 is a positive result, though the ANIA rate of 800 is a clear issue.
This is further discussed in \autoref{sec:gnp-blocksizes}.

\section{Discussion}
\subsection{Scalability issues}
\label{sec:gnp-scalability}
An issue with Gunetti \& Picardi's method is that during authentication, it compares a probe sample to every user profile in the system.
This is of course necessary in identification situations where the system is trying to determine which user is typing, provided that no identity has been claimed in advance.
This is indeed very similar to the method they used for identification, however, comparing a sample to every user profile in the system introduces quite severe scalability issues with regards to computational resources as the number of users grows.
For the experimental setting mentioned, performing authentication for one sample took around 140 seconds on a 2.5Ghz Pentium 4 processor \cite{gnp}, which shows that their authentication algorithm is not practically viable.
However, this on its own does not imply that the A and R measures are impractical, as the \textit{authentication algorithm} is the factor inflating computational costs.

Considering that an identity is already claimed in authentication scenarios, an ideal system would only have to compare probe samples to the profile of the claimed identity.
A compromise could be to only compare the probe sample to a subset of user profiles, as pointed out by the authors.
It should be mentioned that both the original solution and the compromise would require a database with a set of user profiles to be delivered along with the authentication system, as the system so heavily relies on comparing the probe to multiple profiles, as opposed to using a threshold.
Hu et al. \cite{hu} published an improvement to Gunetti and Picardi's solution, which separates training samples into clusters and uses the k-nearest neighbor classifier to only compare probe samples to users in the same cluster as the claimed identity.
While they achieved significantly higher computation speeds (66.7\%), the time to authenticate a user is still very long.

Another scalability issue in the original solution is pointed out by Gunetti and Picardi themselves, which revolves around false rejections.
As seen in the two requirement in \autoref{sec:gnp-algorithm}, a genuine user A who is logged into their own account and has a similar typing pattern to another legal user B could be falsely deemed as an imposter if the sample of A is closer to B's profile.
The authors suggest a remediation to this effect, however, it involves having the authentication system not compare probe samples to other legal users who have similar typing patterns to the claimed identity, something that needs to be processed.
Overall, the authentication algorithm has too many issues for it to be viable for my upcoming master thesis.

\subsection{Block size}
\label{sec:gnp-blocksizes}
The block size used in their experiment is around 800 keystrokes, as mentioned earlier.
This is an important issue, because it means that an imposter can perform 800 keystrokes before their authenticity is even checked, which gives them quite a long period of freedom in the system.
The experimental results for smaller block sizes showed less promising results. 
\autoref{tab:gnp-blocksizes} shows how the ANGA and ANIA rates were negatively affected:

\begin{table}[h]
\centering
\begin{tabular}{ccccc}
 \bf Sample length & \bf FAR (\%) & \bf FRR (\%) & \bf ANIA & \bf ANGA \\
 4/4 & 0.005 & 4.833 & 800 & 16553 \\
 3/4 & 0.029 & 9.333 & 600.17 & 6429\\
 2/2 & 0.063 & 15.5 & 400.116 & 4286
\end{tabular}
\caption{Experimental results using different block (sample) lengths}
\label{tab:gnp-blocksizes}
\end{table}
The ANIA rate is very much tied to the length of the block, which makes sense as the majority of imposters will be detected the first time the periodic authentication triggers.
The ANGA rates reveal important details, as it is clear that they drop significantly as the block size is lowered.
An ANGA rate of 6429 or even 4289 would be annoying for users, as it would result in too many rejections per day.
Therefore, the block size is clearly a major drawback of Gunetti and Picardi's authentication system.

\subsection{Issues regarding enrollment}
While the experimental setting was uncontrolled in the sense that the participants submitted their samples from their own computers without the researchers' presence and supervision, the samples did not necessarily capture the natural behavior of the participants.
As opposed to non-intrusively and continuously capturing keystrokes in the background, the volunteers were instructed to perform a specific task.
One issue is that this could make them more aware of their own typing rhythm, thus cause slight differences compared to their natural typing.

Another potential problem lies in the fact that the volunteers were suggested to write about something they enjoyed, such as holidays or movies.
Kołakowska concludes in \cite{emotion} that emotions definitely affect some keystroke characteristics, which could mean that the authentication system's performance was affected, as mostly one emotion was 'captured'.

Lastly I would like to mention that all samples were written in Italian.
It is not uncommon for bi- or multilingual individuals to write in more than one language during their regular activities.
One may wonder if Gunetti and Picardi's system would perform just as well in such situations.

\chapter{Messerman, Mustafić, Camtepe and Albayrak}
\label{chap:messerman}
In 2011, a paper was published by Messerman et al. \cite{Messerman}, in which they proposed a non-intrusive free-text authentication system based on that of Gunetti and Picardi \cite{gnp}, with an aim to solve the scalability issues discussed in \autoref{sec:gnp-scalability}.
They also address the fact that a user may experience slight changes in their typing pattern over longer periods of time by introducing an \textit{adaptive user model}.

As a user is initially enrolled, they gradually fill up vectors containing single key actions, which are used for extracting n-graph features to build the biometric reference, or \textit{user profile} as they have named it.
As the vectors fill up, a minimum number of full vectors is eventually reached for the authentication system to have enough data to begin periodically authenticating the user.
Instead of stopping the enrollment at this point, more vectors are filled as long as the user is determined to be genuine, up until a maximum amount of vectors.
After reaching the maximum, the user is continually enrolled by overwriting the oldest vectors, so that the reference always contains the most recent behavior associated with the genuine user, always adapting to gradual changes.

The distance measure used is a normalized version of Gunetti and Picardi's R measure.
Recall that the original R measure supports combining distances based on different types of n-graphs such as digraphs and trigraphs based on weighted summation.
This means that the R measure could originally reach values higher than 1.
Messerman et al. \cite{Messerman} normalize the R measure so that the resulting R-distance always is between 0 and 1.

\section{Experimental setting}
\label{sec:messerman-experimental}
The authors developed an e-mail application which could be linked to volunteer's personal and work related e-mail accounts, allowing the authors to collect data passively and unobtrusively while the participants composed their messages.
Almost 300,000 keystrokes were collected from 55 participants over the course of a year, with a majority of them (33) producing over 6000 keystrokes.
15 volunteers produced under 3500 keystrokes.

In their experiments, an authentication attempt was requested after 50 buffered keystrokes, however the classification algorithm relied on having more than 30 shared n-graphs between the probe and each reference template in a user profile. This meant that the effective block size of the PA system was between 50 and 150 keystrokes, which is much less compared to the 800 average block length in Gunetti and Picardi's \cite{gnp} PA system.

\subsection{Algorithm}
The author adopted the same classification algorithm as Gunetti and Picardi \cite{gnp}, however, better scalability was needed.
Since the target application was an e-mail application, which can have thousands or millions of users, comparing new probe templates to the references of every single user of the system would clearly not be viable.
To overcome this challenge, the authors modified the classification algorithm to first check if the mean distance between a new probe and the claimed user's reference is below a certain threshold.
If it is, only then will the next steps of the algorithm commence.
I would like to point out that the only time this step would reduce the use of computational resources is if the distance is higher than the threshold, i.e. when an alleged imposter is immediately detected.
In the general use case where the current user is the genuine one, the entire algorithm would in most cases be used.

If the mean distance to the reference is below the threshold, the algorithm proceeds in a similar way as the original \cite{gnp}.
However, instead of comparing the probe to the references of all users, the modified algorithm compares it to a constant number of users.
The users are selected at random, however the authors mention that a positive side effect to this method is that users with similar typing behavior can be ignored to avoid the problem of falsely rejecting genuine users due to a sample being too similar to another user, as mentioned in \autoref{sec:gnp-scalability}.


\subsection{Performance}
Their experiments showed that the system's performance depended on a number of factors.
One of these factors is the number of other users to compare a probe template to.
They found that increasing this number lowered the FMR rate, which in other words means that imposters were detected more frequently.
As a consequence, the FNMR increased, meaning genuine users would be rejected at a higher rate.
Increasing the total number of users in the application did not seem to affect the performance, both in terms of error rates and computation time.
This makes sense due to the constant number of random users to compare probes to.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{messerman/messerman_thresh1}
    \caption{The distance threshold's effect on error rates as originally displayed in \cite{Messerman}. The scales for FMR and FNMR are on the left and right side of the graph, respectively.}
    \label{fig:messerman-threshold}
\end{figure}

The authors report the PA system's performance by using FAR and FRR, however they distinguish \textit{internal} FAR (iFAR) from \textit{external} FAR (eFAR), depending on whether the attackers are other legal users of the application or unknown adversaries.
As these rates are for the algorithm level, I will hereby use the terms FMR and FNMR as a correction.
A factor that had a significant impact on these rates was the maximum distance (MD) threshold, as seen in \autoref{fig:messerman-threshold}.
The authors further separated each error rate into three rates corresponding to how many iterations of the classification algorithm was performed per probe, which they call \textit{trials}. 
They tested the system for 1, 2 and 3 trials.
For example, "eFAR\_2" represents the external FMR when each every unknown imposter probe is put through two trials before an overall decision is made.
Though it is not explicitly stated, this must mean that a different set of random users was chosen per trial, as not doing so would result in no change of outcome.

As the graph shows, the internal and external FMR was negatively affected by increasing the number of trials, while the effect on FNMR was positive.
More imposters escape detection as they are given more chances per probe, and genuine users are less often wrongfully rejected.
Though both rates are affected, the number of trials affects the FNMR on a much larger scale than the FMRs.
As an example, for a distance threshold of 0.46, the difference in FNMR between two and three trials is approximately 10\%, while the difference in FMR is around 0,5\%.

%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.4\textwidth]{messerman/messerman-perf2}
%    \caption{The results of the experiments in terms of iFMR, eFMR, FMR for \textit{m} trials per decision, with a maximum distance threshold of 0.57. \cite{Messerman}}
%    \label{fig:messerman-perf}
%\end{figure}

\begin{table}[h]
    \centering
    \begin{tabular}{lllllll}
         \bf Trials & \bf eFMR & \bf iFMR & \bf ANIA & \bf FNMR & \bf ANGA\\
         1 & 0.73\% & 0.66\% & 50-150 & 9.48\% & 527--1582 \\
         2 & 1.66\% & 1.33\% & 50-150 & 3.45\% & 1449--4347\\
         3 & 2.61\% & 2.02\% & 50-150 & 1.84\% & 2717--8152\\
    \end{tabular}
    \caption{Performance of the experiment in terms of error rates for \textit{m} trials per decision, with a maximum distance threshold of 0.57 as presented in \cite{Messerman}. ANIA and ANGA columns are added added by me.}
    \label{tab:messerman-perf}
\end{table}

\autoref{tab:messerman-perf} shows the overall performance of their PA system.
As the block length varies between 50--150, the real ANIA and ANGA is impossible to calculate.
However, the authors state that they found an average of 32 shared n-graphs when the block length was 50 and reference sample of length 700, which implies that 50 keystrokes is often enough to perform an authentication.
Therefore, the real ANIA and ANGA are likely around the lower values in the table.

Finally, the authors report an average computation time of 409--554ms per decision on a 1 GHz Pentium 3 processor. 
Compared to Gunetti and Picardi's 140 seconds, this is clearly an improvement, however the fact that a decision is made every 50-150 keystrokes as opposed to 800 must be taken into consideration.

\section{Discussion}
The proposed PA system provides remedies for some of the issues in \cite{gnp}.
One of said issues was the large block size of 800, which has been reduced to 50-150 in \cite{Messerman}.
In terms of ANIA rates, this is a great improvement, as imposters are on average detected after 50-150 keystrokes only.
However, the ANGA rates are also lowered, causing genuine users to be locked out on average after 2717-8152 keystrokes in the best scenario (3 trials).
Compared to Gunetti and Picardi's ANGA of over 16000 keystrokes, this is an obvious downgrade.
Still, considering that the target system is an e-mail application, this would in many cases not result in many lockouts per day, since keystrokes outside of said application would not be recorded.

The proposed adaptive user model is a very interesting addition to the PA system.
Adapting to changes in the user's behavior is something that can have a positive impact on ANGA rates, leading to a better user experience as they are wrongfully locket out less often.
The user model is only updated if the result of a probe sample is a match.
However, imposters will in some cases be falsely accepted, causing the genuine user's profile to be corrupted with the imposter's typing patterns.
The authors mention that this can be prevented by limiting how many trials resulting in non-matches are allowed.
It seems like this could work in certain cases, but if the imposter has a sufficiently similar typing pattern to the genuine user and is accepted by one or more trials, the user profile is already corrupted and will give the imposter higher chances of being accepted in future authentication attempts.
Also, due to the way the authors described this prevention mechanism, it can be assumed that their system favors trials resulting in a match over those who do not.
This is not properly addressed in the article, but \autoref{fig:messerman-threshold} supports this assumption, as a higher number of trials negatively affects FMR and positively affects FNMR.

\subsection{Scalability}
As similarly discussed in \autoref{sec:gnp-scalability}, this system also has a reliance on other users in the application, though only a subset of the total userbase.
The addition of a threshold does however lower this reliance slightly, as it enables the system to perform better with very small userbases and also to function with only one single user.

On the issue of computation speed, the half second response time is more suitable for my master thesis than the 140 seconds in \cite{gnp}.
Even so, this does not necessarily mean that I can use this PA system as a whole, as there are a number of problems to be discussed.

\subsection{Enrollment}
Due to how the authors conducted their experiments, the reported performance is subject to discussion.
Only 3500 keystrokes were needed to build a user profile ready to be used for authentication, which is very efficient both for the length of the enrolment process, as well as for scalability in terms of storage.
Compared to Gunetti and Picardi's user profiles based on $14*800\approx{11200}$ keystrokes \cite{gnp}, a minimum of 3500 is a better fit for an online e-mail application.
The low block size of 50--150 also greatly limits the damage potential for imposters.
If this PA system were to be used for securing an entire operating system though, such as the setting in my master thesis, the experiments in both research articles \cite{gnp, Messerman} are unsatisfactory in captured variance of behavior.
Messerman et al.'s \cite{Messerman} experiments probably captured higher variance, as there was no restriction to language used, and the volunteers were not suggested to write about any certain topics.
As the keystrokes were recorded in the background, the participants were not merely typing text in order to produce samples; they were simply composing e-mails that they otherwise would have written regardless of participating in the experiment.
Still, e-mails tend to have a more formal and thought-out wording compared to other message formats such as online chats.
Also, other behavior such as gaming was not recorded.
It is not known how this system would perform in such scenarios with only 3500 keystrokes being covered.

\subsection{Performance evaluation issues}
When evaluating the performance of the PA system, the authors used various settings and parameters, as already mentioned in \autoref{sec:messerman-experimental}.
When evaluating different performance metrics, they included specific settings in footnotes.
Examples of this are the experiments for investigating how the performance was affected by the total number of users in the userbase as well as the number of users considered in the decision process.
In both of these cases, they used 17 external imposters and 23 internal imposters/legitimate users.
This is a total of 40 users, which fits the number of users producing over 3500 keystrokes: $55-15=40$.
Apart from this, they also showed the settings for investigating the maximum distance threshold's impact on error rates, which is the experiment shown in \autoref{fig:messerman-threshold}.
Here they used 20 external imposters and 30 internal imposters/legitimate users.
At this puts the total involved users as 50, they seem to contradict their own minimum number of keystrokes in the enrollment process.
It is therefore not easy to trust the author's performance evaluations, as they do not explain this contradiction in their article.

Another issue regarding their performance evaluation is the fact that the results in \autoref{tab:messerman-perf} are achieved with a maximum distance threshold of 0.57.
Again, the authors do not explain the reasoning for this specific value.
This leads me to believe that the results are influenced by overfitting, as 0.57 happens to be an optimal threshold as seen in \autoref{fig:messerman-threshold}, especially regarding external FMR for 1 trial, which shows a valley at that threshold.
If the authors indeed overfitted their experiment to their dataset, it is difficult to imagine the true performance of the PA system employed in practice.

Lastly, I would like to mention two unclear issues, with the first being the lack of clarity regarding which n-graphs were considered in the experiments.
They do mention that they found an average of 32 shared digraphs between probe samples of 50 keystrokes and reference samples of 700 keystrokes, however they do not tie this up to the performance evaluations.
Secondly, they do not explain why they only use the R-measure, as opposed to combining it with an A-measure as Gunetti and Picardi did \cite{gnp}.
Seeing performance results for a combined R and A distance would be interesting, both for the effects on error rates and computation speed.

\chapter{Ferreira and Santos}
Another PA system based on Gunetti and Picardi's work was published by Ferreira and Santos in 2012 \cite{superResults}.
They use a block size of 250 keystrokes and also periodically update the user profile after three successfully authenticated attempts, in other words by merging the attempts into a sample of 750 keystrokes to be integrated into the user profile.
While they state that one such sample technically is enough to start the authentication stage, the accuracy would obviously be negatively affected by having such a small biometric reference.
The user profile contains 15 such samples, and during authentication these are \textbf{merged} to one template based on $15*750 = 11250$ keystrokes to be compared to the 250 keystroke probe. 
As new 750 keystroke samples are submitted, the oldest ones in the user profile are replaced by the new samples, not unlike the adaptive user model in Messerman et al.'s PA system \cite{Messerman}.
An important difference between the two systems is that while Messerman et al. only uses the R measure, Ferreira and Santos' system utilizes both R and A measures for distance calculations.
%As opposed to the PA system proposed by Messerman et al. \cite{Messerman} which was discussed in \autoref{chap:messerman}, Ferreira and Santos' system uses both R and A measures for their distance calculations.

They refer to a previous study \cite{superOld}, where they along with a third author describe their own method for calculating A measures.
As shown in \autoref{sec:gnp-algorithm}, Gunetti and Picardi used a threshold of 1.25 in the calculation of A measures to determine whether n-graphs from the probe and reference were similar.
Ferreira and Santos' method takes advantage of standard deviations, as every n-graph of a \textit{subtemplate} has an associated average, standard deviation and number of occurrences.
Subtemplates (called subsamples in original paper) are separated collections of \textbf{dwell times} for single keys, \textbf{flight times} for digraphs and \textbf{durations} for di-, tri- and fourgraphs extracted from a sample.

An example of a subtemplate would be all trigraph durations extracted from a sample.
Then, every trigraph in the subtemplate would have a standard deviation, average duration and number of occurrences within the subtemplate.
Using these values, they calculate the 10\% most consistent n-graphs in every subtemplate, and store a record of them in the user profile.
During comparisons, they apply a lower similarity threshold when comparing n-graphs that are among the 10\% most consistent.
This enables them to place more strict expectations where the genuine user rarely deviates from their usual typing patterns.
They mention that they by default use a similarity threshold of 1.10 for consistent n-graphs and 1.25 for others, and that these are adjusted based on every individual user's timing consistency \cite{superOld}.
Unfortunately, they do not describe exactly how this adjustment is performed.

Taking consistent n-graphs into account, the rest of the A measure is calculated as described in \autoref{chap:gnp}. The R measure is also calculated in the same manner as the original method, and the A and R measure are combined into what they call the \textit{global} distance.
While a probe sample is compared to several other users in \cite{gnp, Messerman}, Ferraira and Santos' PA system bases its decisions solely on a global distance threshold.
Interestingly, the global distance threshold is calculated individually for every user.
This is done computing the global distance between every 750 keystroke sample in the database and the merged reference template, not including their own occurrences.
This can alternatively be viewed as every sample being compared to the 14 other samples.
The average distance of all of these calculations give an expectation of how the genuine user should be performing compared to their own profile.
The global distance threshold is then set to this average distance minus a static degree of tolerance in order to allow for some variations.
This threshold largely affects the error rates, and can be changed to balance FMR and FNMR according to how strict of a system is wanted.
This is further shown in \autoref{sec:ferreira-experiment}.

Another interesting feature that the authors proposed is to asynchronously authenticate the user when certain events happen.
One example could be after a longer period of silence where the genuine user may have left the workstation, an authentication could be triggered after 75 keystrokes.
Then, a sample consisting of the last $175 + 75 = 250$ keystrokes would be tested, in order to potentially catch any imposter who would have taken control of the computer.
Attempting to save or overwrite important files could also trigger this functionality.

\section{Experimental setting}
\label{sec:ferreira-experiment}
60 participants installed a logging software on their computers which captured their keystroke data in the background, never interfering with their daily activities.
The data collection period lasted for two weeks and 15 samples were collected to build user profiles in addition to another 15 samples which were to be used for testing.
These extra samples were used both to simulate genuine access attempts and as imposter attempts, resulting in a total of 900 genuine attempts and 53100 imposter attempts \cite{superResults}.


\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{ferreira/distr}
    \caption{Distribution of scores for genuine and imposter attempts against all user profiles as presented in \cite{superResults}.}
    \label{fig:ferreira-distr}
\end{figure}

The results of the simulations showed an equal error rate of 1.4\%, and they point out a specific setting for the degree of tolerance mentioned earlier which gives a 0.5\% FMR and 2.7\% FNMR.
This translates to an ANIA of $250 / (1-0.005) \approx{251}$, and ANGA of $250 / 0.055 \approx{4545}$, which will be discussed in \autoref{sec:ferreira-discussion}.
They also found that there was a clear distinction between genuine and imposter attempts, as seen in \autoref{fig:ferreira-distr}.
Note that I have intentionally been referring to their matching "score" as a distance measure in order to more easily show their system's relation to the other PA systems using R and A measures. 
Distances and match scores generally work in the same way, and a distribution of distances would have the red and green dots in \autoref{fig:ferreira-distr} swap places.
While some of the users generally have lower scores to their own profiles, the imposters score even worse, indicating that having custom distance thresholds for every user benefits the performance of the overall system.

The authors also created a prototype of the PA system for testing it in real time, though at a smaller scale than the simulations.
Ten participants each produced a fixed reference sample of 200 keystrokes, and testing was conducted by having one genuine attempt and a random person acting as an impostor. This was done in 200 iterations, and resulted in a 0.5\% FMR and a 5.5\% FNMR, which shows that the smaller sample size negatively affected the FNMR, and thus also affected the ANGA which in this case was .

\section{Discussion}
\label{sec:ferreira-discussion}
Ferreira and Santos' PA system seems particularly fitting for my master thesis, as its intention to be used for protecting an entire workstation by observing keyboard input in all applications and contexts is similar to that of Mondal's CA system which I will be extending \cite{mondal}.
The experiment's uncontrolled data collection phase also matches Mondal's experiment quite well, which makes comparing the systems more sensible.
As I will be using Mondal's database for my own project, I am likely to receive similar results when applying Ferreira and Santos' methods to it, as the data should have similar amounts of variation in typing behavior per user.

While their method for asynchronous authentication is a great measure for possibly detecting imposters even earlier than the block size originally allows, and even on special triggers, this is mostly relevant for actual real-time implementations of the software.
My master thesis will revolve around simulations and analysis, and I could therefore omit this functionality if I were to integrate this PA system into the CA system.
The CA system already tries to detect imposters as early as possible, and for that reason partly covers the intended motivation for the proposed asynchronous authentication.

\subsection{Classification}
A great feature of the PA system is its sole reliance on a user-fitted global distance threshold.
Not only does this ensure that users who tend to score poorly against their own biometric reference still can use the PA system with satisfying performance, but it also lets the system avoid involving other users in the classification process.
As the PA system operates application-wide, one can imagine a scenario where college campus computers would install the PA system.
Such computers are accessible by thousands of students, and comparing the typing patterns of one user to every other registered student such as Gunetti and Picardi's original system would do \cite{gnp} is clearly not practical.
While Messerman et al. \cite{Messerman} would not show the same scalability issues due to only including a subset of all students, Ferreira and Santos' system inherently avoids the potential problem of having a genuine user falsely rejected due to their probe sample haphazardly being more similar to another student's behavior than that of their own.

While not involving other users positively affects the scalability of the PA system, their 

%mention asynch for real life implementations
\subsection{Follow-up study}



%Their authentication system uses a short block size and also periodically updates user profiles, similarly to Messerman et al.'s system \cite{Messerman}.

%Positive: Doesn't rely on other users! Only threshold based! - can be changed according to liberal / strict environments (must avoid overfitting though)
%Positive: Good performance with SMALL probe samples!
%Positive: Gives ROC curve. Prevents us from only seeing overfitted performance evaulations.
%Positive: Tested in real life.
% Asynch, though as I won't be making a real application, I could omit this. The CA system partly covers the intended motivation for this anyway.

% https://link.springer.com/chapter/10.1007%2F978-3-662-44885-4_3#copyrightInformation


%Negative: Quite large user profiles, same as GNP: 15*750. Much larger than 3500.
%Negative: Doesn't mention computation time. Though, it should not be high at all, as probes are only compared to genuine user profile.
%Negative: does not mention n-graphs, though seems from figure 
%Negative: Adaptive user model, intrusions would alter the DB (though I can disable this for my simulations in master)
%Negative: experiment #2 was static text.. doesnt say very much tbh



%Negative NN: comp. heavy. Also, needs to be retrained for every change to profile.

% http://ieeexplore.ieee.org/document/7529146/ this one seems pretty good
%NOTE: SLIDING? \cite{sliding}. Probably worth writing about
%NOTE: VILLANI MAY BE WORTH INCLUDING BECAUSE OF EUCLIDIAN DISTANCE
% https://www.hindawi.com/journals/tswj/2013/408280/talks about machine learning
\chapter{Concluding discussion}



%NOTE: FIX BIB STYLE
\bibliographystyle{plain}
%\bibliographystyle{gucmasterthesis}
\bibliography{bib}



\end{document}





%IEEE computer society keywords
%http://www.computer.org/portal/site/ieeecs/menuitem.c5efb9b8ade9096b8a9ca0108bcd45f3/index.jsp?&pName=ieeecs_level1&path=ieeecs/publications/author/keywords&file=ACMtaxonomy.xml&xsl=generic.xsl&
