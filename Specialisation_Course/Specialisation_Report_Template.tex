\newcommand{\comment}[1]{}

%\documentclass[a4paper,twocolumn,12pt]{article}

%\documentclass[a4wide,12pt]{report}

%\documentclass[a4wide,12pt]{article}
%\documentclass[informasjonssikkerhet]{gucmasterproject}
%\documentclass[informationsecurity]{gucmasterproject}
\documentclass[informationsecurity]{gucmasterproject}

%\usepackage{pslatex} %% Doesn't seem to work - i.e. convert .eps to .pdf
 
\usepackage[utf8]{inputenc}     % For utf8 encoded .tex files
%\usepackage[latin1]{inputenc}
\usepackage[british]{babel}     % For chapter headings etc.
%\usepackage[pdftex]{graphicx}           % For inclusion of graphics

%From http://math.uib.no/it/tips/
   %% For grafikk
    \usepackage{ifpdf}
    \ifpdf
      \usepackage[pdftex]{graphicx}
      \usepackage{epstopdf}
    \else
      \usepackage[dvips]{graphicx}
    \fi
    %% Her kan du putte dine vanlige pakker og definisjoner



%\usepackage[dvips]{hyperref}    % For cross references in pdf
\usepackage{hyperref}
\usepackage{mdwlist}
\usepackage{url}
\usepackage{here}

\def\UrlFont{\tt}

\begin{document}

\thesistitle{A survey of periodic authentication systems based on keyboard dynamics}
\thesisauthor{Per-Kristian Nilsen}
\thesisdate{\gucmasterthesisdate}
\useyear{2017}
\makefrontpages % make the frontpages
%\thesistitlepage % make the ordinary titlepage


\comment{
Front page - including
"   NTNU technical report front page including logos etc.
"   The text: "Specialization Report"
"   Title of project
"   Name of author and contact details
"   Date
"   Version

email address
"   MIS students must include "NISlab" as their affiliation.
Date:22.10.2003

Structure of Specialization Report
NTNU in Gj\o{}ovik
}



\begin{abstract}


\end{abstract}


\tableofcontents

\chapter{Introduction}
Biometrics is increasingly utilized for user authentication, with fingerprint readers being built into personal devices such as smart phones and laptops.
Biometric systems based on modalities such as fingerprint, hand print, iris, retina and facial recognition are to varying degrees now known to the general public.
A common feature of these modalities are that they are \textit{biological} -- they are based on our individual anatomy.
On the other hand, \textit{behavioral} biometric systems are not yet as widely used as its physiological counterpart, largely due to lesser reliability and being more prone to changes over time.

Behavioral biometrics are, as the name implies, based on the behavior of an individual. Behavioral modalities include (but are not limited to) gait recognition, voice recognition, mouse dynamics and keyboard dynamics, with the latter being the focus of this literature study.
'Keyboard dynamics' is a term revolving around capturing the features from a person's typing rhythm, and using them for purposes such as user authentication, identification and classification.
\textit{Identification} means determining whether or not a person is a known user of a system, and if so, who it is.
\textit{Classification} is the process of determining who a person is within a set of possible individuals, while \textit{authentication} is verifying whether or not a person is who they claim to be.

These systems may be used either to \textit{give access} or to \textit{remove access}.
Similar to password based authentication, keystroke dynamics can be utilized for initial \textit{static (one-time) authentication}, \textit{giving} a legal user access to their system if it is apparent that the typing user is the \textit{genuine} user of the claimed identity.
One approach to this kind of authentication is having a user write a predetermined and fixed sample text of which typing features are extracted to form a probe to be compared to their previously enrolled reference.
The text may be short or long, depending on the authentication system at hand.  
An example of a short text may the user's password, while long text could be a short news article.

\textit{Dynamic authentication} generally takes place after static authentication, and \textit{removes access} if the current user is believed to be an imposter, i.e. someone other than the genuine user of the logged in account.
The user is repeatedly authenticated throughout their session, as an additional layer of security on top of the static authentication.
Again, both fixed- and free-text can be used for this purpose.
There are two approaches to free-text dynamic authentication, namely \textit{continuous} and \textit{periodic} authentication, both of which rely on passively monitoring the user's typing behavior, and determining whether the current user is the genuine user of the logged-in account.
Periodic authentication (PA) systems rely on passively recording a \textit{block} sample of keystrokes of which features are extracted from to generate a probe when the block is filled.
These features are then compared to the reference, similarly to the static authentication systems previously mentioned.
The authors of PA systems have a tendency of calling their methods "continuous authentication" (CA), but as Bours \cite{BOURS201236} pointed out, the term "continuous" implies that the authentication process is performed after each individual keystroke.
I will therefore refer to all PA systems in the literature as "periodic", regardless if the authors themselves refer to their methods as "continuous".

CA systems such as the one proposed in \cite{BOURS201236} only considers the last keystroke plus its relation to the keystroke before (if any).
Similarly to PA systems, these features are then compared to the reference, however, CA systems have much less statistics to work with compared to PA systems.
The upside to CA systems is that they react instantly to every user action, such as increasing or lowering the trust in the user's genuineness in Bours' system \cite{BOURS201236}.
On the contrary, PA systems cannot react to impostors until enough keystrokes have occured to fill the block.
Until that happens, the impostor has free reign over the genuine user's account in the system.

The features extracted from keystrokes vary between different systems.
For single key actions, there are two events happening, namely Key Down and Key Up, which means pressing and releasing the key, respectively.
Timestamps are associated with these events, usually at the granularity of milliseconds.
From these timestamps, the \textit{duration/dwell time} of the keypress can easily be determined.
When two or more sequential keypresses (n-graphs) are to be considered in relation to each other, a number of features can be extracted.
As an example, the \textit{digraph} 'AB' may have the timing values as shown in \autoref{tab:timing-example}.
From those values, one could extract the durations of the single keys, but also the following features: 

\begin{itemize}
\item A\textsubscript{down}--B\textsubscript{down} (latency)
\item (A\textsubscript{down}--B\textsubscript{up}) (duration)
\item (A\textsubscript{up}--B\textsubscript{down}) (flight time)
\item (A\textsubscript{up}--B\textsubscript{up}) (latency)
\end{itemize}
The respective latency values would then be 45, 60, 25 and 40 milliseconds, calculated by subtracting the timestamp of the first key from the timestamp of the second key.
The authentication system could then use these features to calculate the similarity to the reference template for instance by using one or more distance measures, or by using machine learning algorithms.

\begin{table}[h]
    \centering
    \begin{tabular}{lll}
         \bf Key & \bf Action & \bf Timestamp (ms)\\
         A & Down & 80\\
         A & Up & 100\\
         B & Down & 125\\
         B & Up & 140
    \end{tabular}
    \caption{Example timing values for 'AB' digraph.}
    \label{tab:timing-example}
\end{table}

Another difference between PA and CA systems in literature is the way performance is reported.
False Accept Rate (FAR), False Reject Rate (FRR) and Equal Error Rate(EER) are generally used for indicating the performance of PA classification algorithms.
FAR represents the percentage of imposters being falsely accepted, which indicates the security level of the system. 
FRR represents the percentage of genuine users being falsely rejected, which has implications for user acceptance, as being rejected too often would be a source of irritation.
These two rates are inversely proportional to each other, as lowering the FAR inherently increases the FRR.
The ERR therefore shows the point where the FAR and FRR of a system have the same value.
These rates must be looked at in relation to the PA system's block size in order to be meaningful.
I would also like to mention that much of the PA literature misuses the FAR and FRR terms, as they are system-level evaluation metrics, and they are often wrongly used to describe the performance of their classification algorithms.
According to the vocabulary specified in the ISO/IEC 2382-37 standard \cite{ISO-voc}, the correct terms for algorithm level performance is False Match Rate (FMR) and False Non-Match Rate (FNMR), and I will replace wrongly used terms where applicable when discussing the literature.

Bours and Mondal proposed in 2015 two new metric for evaluating the performance of CA systems, namely Average Number of Imposter Actions (ANIA) and Average Number of Genuine Actions (ANGA) \cite{CA-performance}.
These rates look at how many actions imposters and genuine users on average can perform before being rejected by the authentication system, as it often is more useful to know how often users will be locked out than the probability of that happening per sample.
They also provide formulas for converting PA systems' FAR into ANIA rates and FRR into ANGA rates.

The purpose of this literature review is to prepare for my upcoming master thesis on combining CA and PA systems.
I will be extending the CA system proposed in Soumik Mondal's PhD thesis \cite{mondal} with a PA system in order to determine if the combination of such systems can have positive effects on performance.
The performance metrics used in said CA system is ANIA and ANGA, and I will therefore use the conversion formulas from \cite{CA-performance} in order to easily compare the performance of PA systems to the CA system's performance.
%NOTE: Maybe good at some point in chapter 1 to mention that you study the PA systems as they are described, but will most likely implement parts of it only in your master thesis when combining them with the CA system.

%NOTE: write more about purpose of this document.
%NOTE: Include description of sections.



%\chapter{Project description evaluation criteria}

%\chapter{Enrollment}
%The enrollment phase of the different papers written on periodic authentication have varying approaches to collecting data for generating reference templates.
%This chapter will cover the approaches most relevant to my master thesis and contain a discussion on which of them, if any, are applicable.
%
%After gathering participants, their keystroke data must be recorded.
%In my case, this phase will last a longer period of time, as the data will be recorded in a completely uncontrolled environment.
%Specifically, the participants will be installing software on their private computers, and the software will record all keyboard activity for as long as the enrollment phase lasts.

%\chapter{Feature extraction}
%While the CA system will consider timing data for monographs, the PA system will likely have focus on digraphs, or possibly n-graphs of greater length.


\chapter{State of the art}
This chapter will contain a summary of the state of the art, with a similar format to that in Mondal's PhD thesis.
The following chapters are discussions of individual PA systems.
Should I have a chapter explaining Mondal's CA system?
\\\\\\\\
%NOTE: Write about what systems use which n-graphs
%NOTE: Remove following text.
%NOTE: http://onlinelibrary.wiley.com/doi/10.1002/cpe.3718/full HAS A GOOD OVERVIEW OF STATE OF THE ART. 
%NOTE: http://www.sciencedirect.com/science/article/pii/S1568494617305847 THIS ONE TOO
%NOTE: https://www.hindawi.com/journals/tswj/2013/408280/ HAS A LOT OF DIFFERENT POINTS TO TALK ABOUT IN STATE OF ART
Following is a (very) temporary version of what the state of the art overview table may look like.
This will be gradually extended as I write about more papers.
This is mostly just to show what types of information is to be included in the final version.
\begin{table}[h]
\begin{tabular}{ |c|c|c|c|p{1.5cm}|p{1.9cm}|p{2cm}|p{1.5cm}| } 
 \hline
 \bf Paper & \bf Block & \bf Users & \bf Uncontr. & \bf Method & \bf Perf. & \bf Notes & n-graphs\\ \hline
 \bf Messerman & 50 - 150 & 55 & Webmail & R\&A &  FAR 2.02\% FRR 1.84\% & adaptive user model & \\ \hline
 \bf Ferreira & 250 & 60 & Yes & R\&A & EER 1.4\% & Updates user profile, also triggers authentication asynch & Dw, Fl, 2, 3, 4\\ \hline
 Davoudi(2) & & & & & & & \\ \hline
 %Singh &- & - & - & - & - & STATIC AUTHENT. DONT BOTHER & \\ \hline
 Kaneko & ~200 & 51 & No & Euclidian & 0.66\% EER & Static fixed text, jap. & di \\ \hline
 Ahmed & 500 & 53 & Yes & Neural Networks & FAR 0.0152\% FRR 4.82\% ERR 2.45\% & & mono di\\\hline
 Gunetti & 800 & 40 & Webform & R\&A & FAR 0.005\% FRR 4.833\% & & 2,3,4\\ \hline
 \bf Hu et al. & 36 & 19 & Webform & R\&A, k-NN & FAR 0.045\% FRR 0.005\% & Static text & - \\ \hline
 \cite{Pinto2014} & 150 & 10 & Uncontr & R\&A & FMR ~2\% FNMR ~2\% & Lacks clarity & Dw, Fl, 2, 3, 4 \\ \hline
 \cite{900words} & ~ 900 words & 2000 & No & KRR, TRBF & EER 1.39\% & Final decision after all words in test set & Tri
 
\end{tabular}
\end{table}


\chapter{Gunetti \& Picardi}
\label{chap:gnp}
An interesting method for authenticating users was proposed by Gunetti \& Picardi in 2005 in a paper which became highly cited due to its promising results \cite{gnp}.
Their system uses two distance measures, namely absolute (A) and relative (R) measures between samples.
The R and A measures are summed to produce a final distance.
Following is a summary of how the R and A measures are calculated.

Given an attempt sample and a stored sample, a probe and reference is built by extracting the n-graphs shared by both samples into feature vectors sorted by n-graph durations (for instance the time between pressing the first and second key). 
The relative distance between the probe and reference can then be calculated as follows.
The position of each n-graph in the probe is compared to the position of the same n-graph in the reference, producing a position distance for every n-graph.
The position distances between all the n-graphs are then summed before being normalized, resulting in an R measure.
Normalization is performed by dividing the summed differences by the maximum disorder possible in an array with length equal to the number of shared n-graphs.

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{gunetti/R-measure}
    \caption{Computation of relative distance between samples with shared digraphs (a) and trigraphs (b), as presented in \cite{gnp}.}
    \label{fig:R-measure}
\end{figure}

\autoref{fig:R-measure} demonstrates the comparison between samples.
An attempt sample containing the word \textit{authentication} and a stored sample containing the word \textit{theoretical} have their shared n-graphs extracted into the respective feature vectors E1 and E2.
Shared digraphs are shown in (a) and shared trigraphs are shown in (b). 
As pointed out by the authors, the summed position distances in (a) is $2+0+2+3+1=8$.
As there are five shared digraphs, the maximum disorder of the array is $(5^2-1)/2=12$.
Therefore, the R distance between E1 and E2 in (a) is $8/12 = 0.666$.

A method for combining relative distances based on more than one n-graph is also provided, where the relative distances of the different n-graphs are weighed based on the number of shared n-graps they contain. 
In the example above, (a) and (b) would be combined by summation with weights 5 and 3, respectively.
The reason for these weights is that a distance becomes more meaningful as the number of n-grams it is based on increases, and (a) is in this case the more meaningful case.

The authors state that the purpose of the R measure is to account for differences in typing speed that affect all n-graphs similarly.
They explain this with the example of someone with a headache possibly typing slower, but doing so for all text they input.
It is worth mentioning that this could also be the case if the subject has cold fingers, is under the influence of alcohol or other substances, or a number of other factors.
While everything is typed slower, the \textit{relative} speed between different n-grams in the same sample is likely to be similar to the relative speed between n-grams in another sample where they were typing at normal speed.

On the other hand, the A measure takes the absolute speed of corresponding n-graphs in two samples into account, as the absolute speed of an imposter's typing pattern is less likely to be similar to the reference than that of the genuine user.
For this measure to be calculated, shared n-graphs in an attempt sample and stored sample are compared and deemed to either be \textit{similar} or not.
If the durations for these n-graphs are different from eachother, they are regarded as \textit{similar} if the longer duration divided by the shorter duration is between 1 and an arbitrary threshold.
Their reason for using a threshold instead of relying on standard deviation is that it enables them to use n-graphs which only occur once in the samples.
The authors chose 1.25 as the threshold for their experiments after testing various thresholds on the data of the five first subjects in their experiment, to avoid overfitting.
Then, they define the A measure of two samples as 1 -- (number of similar n-graphs between the samples) / (total number of n-graphs shared between the samples).

For example, for the (b) case in \autoref{fig:R-measure}, we can calculate the A measure with a threshold of 1.25 as seen in \autoref{tab:gnp-similar}.
The only similar trigraph pair is 'ica', which means that the A measure for E1 and E2 is $1-(1/3)=0.66$.
In a case where the threshold was set to 1.35, both the 'ica' and 'the' pairs would be regarded as similar, resulting in an A distance measure of $1-(2/3)=0.33$.
\begin{table}[h]
\centering
\begin{tabular}{ccccc}
 \bf Trigraph & \bf E1 & \bf E2 & \bf Calculation &  \\
 tic & 370 & 540 & $540/370=1.46$ &  \\
 ica & 430 & 420 & $430/420=1.02$ & (similar) \\
 the & 450 & 340 & $450/340=1.32$ & 
\end{tabular}
\caption{Similarities between trigraphs from \autoref{fig:R-measure}.}
\label{tab:gnp-similar}
\end{table}

\section{Experimental setting}
For their experiment, they had 40 volunteers submitting 15 samples each, consisting of text written in a webform. On average, the sample length was around 800 characters.
14 of these samples were used to build a user profile, while the remaining sample was used as a probe.
Another 165 volunteers were asked to provide only one sample each, which was to be used as impostor samples for attacking the genuine user profiles.
The users were asked to only submit one sample per day, though they were free to wait longer between each sample.
The samples were generally collected from the volunteers' workstations and notebooks, and were all written as free-text.

\subsection{Algorithm}
\label{sec:gnp-algorithm}
Suppose a user is claiming the identity of a specific user A (by being logged into A's account) produces a sample X with a certain \textit{mean distance} to every sample in A's profile, denoted by md(A,X).
For X to be recognized as a genuine sample from user A, both of the following requirements must hold \cite{gnp}:

\begin{enumerate}
\item md(A,X) is the smallest with respect to any other md(B,X), where B is another legal user of the system.
\item md(A,X) is smaller than the mean distance between all samples in A's profile m(A), \textbf{or} md(A,X) is closer to m(A) than to any other md(B,X).
\end{enumerate}
Involving all users in the process is rather counterintuitive for an authentication algorithm.
This is further discussed in \autoref{sec:gnp-scalability}.
\subsection{Performance}
The best performance of their system was achieved using a summation of R and A distances for 2-, 3-, and 4-graphs, reaching an FMR of 0.005\% and an FNMR of 4.833\%, though they call the rates "Imposter Pass Rate (IPR)" and "False Alarm Rate (FAR)".
By using the formula provided in \cite{CA-performance}, we can convert these rates to ANIA and ANGA rates:

\begin{equation}
ANIA = \frac{block size}{(1-FMR)} = \frac{800}{(1-0.00005)} \approx 800
\end{equation}

\begin{equation}
ANGA = \frac{block size}{FNMR} = \frac{800}{0.04833} \approx 16553 
\end{equation}
The ANGA rate of 16553 is a positive result, though the ANIA rate of 800 is a clear issue.
This is further discussed in \autoref{sec:gnp-blocksizes}.

\section{Discussion}
\subsection{Scalability issues}
\label{sec:gnp-scalability}
An issue with Gunetti \& Picardi's method is that during authentication, it compares a probe to every user profile in the system.
This is of course necessary in identification situations where the system is trying to determine which user is typing, provided that no identity has been claimed in advance.
This is indeed very similar to the method they used for identification, however, comparing a sample to every user profile in the system introduces quite severe scalability issues with regards to computational resources as the number of users grows.
For the experimental setting mentioned, performing authentication for one sample took around 140 seconds on a 2.5Ghz Pentium 4 processor \cite{gnp}. 
While the execution time would be substantially faster with modern hardware, the authentication algorithm is inherently inefficient, and should be replaced if I were to use parts of this PA system for my master project, such as the R and A measures.

Considering that an identity is already claimed in authentication scenarios, an ideal system would only have to compare probes to the profile of the claimed identity.
A compromise could be to only compare the probe sample to a subset of user profiles, as pointed out by the authors.
It should be mentioned that both the original solution and the compromise would require a database with a set of user profiles to be delivered along with the authentication system, as the system so heavily relies on comparing the probe to multiple profiles, as opposed to using a threshold.
Hu et al. \cite{hu} published an improvement to Gunetti and Picardi's solution, which separates training samples into clusters and uses the k-nearest neighbor classifier to only compare probes to users in the same cluster as the claimed identity.
While they achieved significantly higher computation speeds (66.7\%), the time to authenticate a user is still very long.

Another scalability issue in the original solution is pointed out by Gunetti and Picardi themselves, which revolves around false rejections.
As seen in the two requirement in \autoref{sec:gnp-algorithm}, a genuine user A who is logged into their own account and has a similar typing pattern to another legal user B could be falsely deemed as an imposter if the sample of A is closer to B's profile.
The authors suggest a remediation to this effect, however, it involves having the authentication system not compare probes to other legal users who have similar typing patterns to the claimed identity, something that needs to be processed.
Overall, the authentication algorithm has too many issues for it to be viable for my upcoming master thesis.

\subsection{Block size}
\label{sec:gnp-blocksizes}
The block size used in their experiment is around 800 keystrokes, as mentioned earlier.
This is an important issue, because it means that an imposter can perform 800 keystrokes before their authenticity is even checked, which gives them quite a long period of freedom in the system.
The experimental results for smaller block sizes showed less promising results. 
\autoref{tab:gnp-blocksizes} shows how the ANIA rates were improved whereas the ANGA rates were negatively affected:

\begin{table}[h]
\centering
\begin{tabular}{ccccc}
 \bf Sample length & \bf FMR (\%) & \bf FNMR (\%) & \bf ANIA & \bf ANGA \\
 4/4 & 0.005 & 4.833 & 800 & 16553 \\
 3/4 & 0.029 & 9.333 & 600.17 & 6429\\
 2/2 & 0.063 & 15.5 & 400.116 & 4286
\end{tabular}
\caption{Experimental results using different block (sample) lengths. Original table from \cite{gnp} is extended with ANIA and ANGA rates.}
\label{tab:gnp-blocksizes}
\end{table}
The ANIA rate is very much tied to the length of the block, which makes sense as the majority of imposters will be detected the first time the periodic authentication triggers.
The ANGA rates reveal important details, as it is clear that they drop significantly as the block size is lowered.
An ANGA rate of 4289 or even 6429 would be annoying for users, as it would result in too many rejections per day.
Therefore, the block size is clearly a major drawback of Gunetti and Picardi's authentication system.

\subsection{Issues regarding enrollment}
While the experimental setting was uncontrolled in the sense that the participants submitted their samples from their own computers without the researchers' presence and supervision, the samples did not necessarily capture the natural behavior of the participants.
As opposed to non-intrusively and continuously capturing keystrokes in the background, the volunteers were instructed to perform a specific task.
One issue is that this could make them more aware of their own typing rhythm, thus cause slight differences compared to their natural typing.

Another potential problem lies in the fact that the volunteers were suggested to write about something they enjoyed, such as holidays or movies.
Kołakowska concludes in \cite{emotion} that emotions definitely affect some keystroke characteristics, which could mean that the authentication system's performance was affected, as mostly one emotion was 'captured'.

Lastly I would like to mention that all samples were written in Italian.
It is not uncommon for bi- or multilingual individuals to write in more than one language during their regular activities.
One may wonder if Gunetti and Picardi's system would perform just as well in such situations.

\chapter{Messerman, Mustafić, Camtepe and Albayrak}
\label{chap:messerman}
In 2011, a paper was published by Messerman et al. \cite{Messerman}, in which they proposed a non-intrusive free-text authentication system based on that of Gunetti and Picardi \cite{gnp}, with an aim to solve the scalability issues discussed in \autoref{sec:gnp-scalability}.
They also address the fact that a user may experience slight changes in their typing pattern over longer periods of time by introducing an \textit{adaptive user model}.

As a user is initially enrolled, they gradually generate samples which are used for extracting n-graph features to build the biometric reference, or \textit{user profile} as they have named it.
After a certain minimum amount of sample data is generated, the process of periodically authenticating the user can begin, though the accuracy increases as the reference grows.
Therefore, instead of stopping the enrollment at this point, more sample data is stored as long as the user is believed to be genuine, up until a maximum amount is collected.
After reaching the maximum, the user is continually enrolled by overwriting the oldest stored sample data, so that the reference always contains the most recent behavior associated with the genuine user, always adapting to gradual changes.

The distance measure used is a normalized version of Gunetti and Picardi's R measure.
Recall that the original R measure supports combining distances based on different types of n-graphs such as digraphs and trigraphs based on weighted summation.
This means that the R measure could originally reach values higher than 1.
Messerman et al. \cite{Messerman} normalize the R measure so that the resulting R-distance always is between 0 and 1.

\section{Experimental setting}
\label{sec:messerman-experimental}
The authors developed an e-mail application which could be linked to volunteer's personal and work related e-mail accounts, allowing the authors to collect data passively and unobtrusively while the participants composed their messages.
Almost 300,000 keystrokes were collected from 55 participants over the course of a year, with a majority of them (33) producing over 6000 keystrokes.
15 volunteers produced under 3500 keystrokes.

In their experiments, an authentication attempt was requested after 50 buffered keystrokes, however the classification algorithm relied on having more than 30 shared n-graphs between the probe and each reference in a user profile. This meant that the effective block size of the PA system was between 50 and 150 keystrokes, which is much less compared to the 800 average block length in Gunetti and Picardi's \cite{gnp} PA system.

\subsection{Algorithm}
The author adopted the same classification algorithm as Gunetti and Picardi \cite{gnp}, however, better scalability was needed.
Since the target application was an e-mail application, which can have thousands or millions of users, comparing new probes to the references of every single user of the system would clearly not be viable.
To overcome this challenge, the authors modified the classification algorithm to first check if the mean distance between a new probe and the claimed user's reference is below a certain threshold.
If it is, only then will the next steps of the algorithm commence.
I would like to point out that the only time this step would reduce the use of computational resources is if the distance is higher than the threshold, i.e. when an alleged imposter is immediately detected.
In the general use case where the current user is the genuine one, the entire algorithm would in most cases be used.

If the mean distance to the reference is below the threshold, the algorithm proceeds in a similar way as the original \cite{gnp}.
However, instead of comparing the probe to the references of all users, the modified algorithm compares it to a constant number of users.
This subset of users is selected at random, however the authors mention that a positive side effect to this method is that during authentication, they can avoid including other users with similar typing behavior to the claimed identity's user profile in the subset. 
That way, if the current user is truly the genuine user, the problem of falsely being rejected due to a sample being too similar to another user can be avoided. 
This problem was mentioned in \autoref{sec:gnp-scalability}, however the suggested exclusion of similar user profiles seems like a worrisome way of improving performance, as it partly contradicts the purpose of including other users in the authentication algorithm.
If an imposter writes similarly to the genuine user but even more similarly to some other user in the system, we would want them to be locked out on this basis.
Excluding users that have similar typing patterns to the claimed identity would inhibit this and likely increase FMR.

\subsection{Performance}
Their experiments showed that the system's performance depended on a number of factors.
One of these factors is the number of other users to compare a probe to.
They found that increasing this number lowered the FMR rate, which in other words means that imposters were detected more frequently.
As a consequence, the FNMR increased, meaning genuine users would be rejected at a higher rate.
Increasing the total number of users in the application did not seem to affect the performance, both in terms of error rates and computation time.
This makes sense due to the constant number of random users to compare probes to.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{messerman/messerman_thresh1}
    \caption{The distance threshold's effect on error rates as originally displayed in \cite{Messerman}. The scales for FMR and FNMR are on the left and right side of the graph, respectively.}
    \label{fig:messerman-threshold}
\end{figure}

The authors report the PA system's performance by using FAR and FRR, however they distinguish \textit{internal} FAR (iFAR) from \textit{external} FAR (eFAR), depending on whether the attackers are other legal users of the application or unknown adversaries.
As these rates are for the algorithm level, I will hereby use the terms FMR and FNMR as a correction.
A factor that had a significant impact on these rates was the maximum distance (MD) threshold, as seen in \autoref{fig:messerman-threshold}.
The authors further separated each error rate into three rates corresponding to how many samples of 50 keystrokes were run through the classification algorithm before a final decision was made.
They refer to these runs as \textit{trials}, and they tested the system for 1, 2, and 3 trials.
For example, "eFAR\_2" represents the external FMR when the final decision is based on two trials. 

As \autoref{fig:messerman-threshold} shows, the internal and external FMRs were negatively affected by increasing the number of trials, while the effect on FNMR was positive.
More imposters escape detection as they are given more chances per probe, and genuine users are less often wrongfully rejected.
Though both rates are affected, the number of trials affects the FNMR on a much larger scale than the FMRs.
As an example, for a distance threshold of 0.46, the difference in FNMR between one and three trials is slightly more than 10\%, while the difference in FMR is around 1\%.

%\begin{figure}[h]
%    \centering
%    \includegraphics[width=0.4\textwidth]{messerman/messerman-perf2}
%    \caption{The results of the experiments in terms of iFMR, eFMR, FMR for \textit{m} trials per decision, with a maximum distance threshold of 0.57. \cite{Messerman}}
%    \label{fig:messerman-perf}
%\end{figure}

\begin{table}[h]
    \centering
    \begin{tabular}{lllllll}
         \bf Trials & \bf eFMR & \bf iFMR & \bf ANIA & \bf FNMR & \bf ANGA\\
         1 & 0.73\% & 0.66\% & 50-150 & 9.48\% & 527--1582 \\
         2 & 1.66\% & 1.33\% & 50-150 & 3.45\% & 1449--4347\\
         3 & 2.61\% & 2.02\% & 50-150 & 1.84\% & 2717--8152\\
    \end{tabular}
    \caption{Performance of the experiment in terms of error rates for \textit{m} trials per decision, with a maximum distance threshold of 0.57 as presented in \cite{Messerman}. ANIA and ANGA columns are added added by me.}
    \label{tab:messerman-perf}
\end{table}

\autoref{tab:messerman-perf} shows the overall performance of their PA system.
As the block length varies between 50--150, the real ANIA and ANGA is impossible to calculate.
However, the authors state that they found an average of 32 shared n-graphs when the block length was 50 and stored samples of length 700, which implies that 50 keystrokes is often enough to perform an authentication.
Therefore, the real ANIA and ANGA are likely around the lower values in the table.

Finally, the authors report an average computation time of 409--554ms per decision on a 1 GHz Pentium 3 processor. 
Compared to Gunetti and Picardi's 140 seconds, this is clearly an improvement, however the fact that a decision is made every 50-150 keystrokes as opposed to 800 must be taken into consideration.

\section{Discussion}
The proposed PA system provides remedies for some of the issues in \cite{gnp}.
One of said issues was the large block size of 800, which has been reduced to 50-150 in \cite{Messerman}.
In terms of ANIA rates, this is a great improvement, as imposters are on average detected after 50-150 keystrokes only.
However, the ANGA rates are also lowered, causing genuine users to be locked out on average after 2717-8152 keystrokes in the best scenario (3 trials).
Compared to Gunetti and Picardi's ANGA of over 16000 keystrokes, this is an obvious downgrade.
Still, considering that the target system is an e-mail application, this would in many cases not result in many lockouts per day, since keystrokes outside of said application would not be recorded.

The proposed adaptive user model is a very interesting addition to the PA system.
Adapting to changes in the user's behavior is something that can have a positive impact on ANGA rates, leading to a better user experience as they are wrongfully locket out less often.
The user model is only updated if the result of a probe is a match.
However, imposters will in some cases be falsely accepted, causing the genuine user's profile to be corrupted with the imposter's typing patterns.
The authors mention that this can be prevented by limiting how many trials resulting in non-matches are allowed.
It seems like this could work in certain cases, but if the imposter has a sufficiently similar typing pattern to the genuine user and is accepted by one or more trials, the user profile is already corrupted and will give the imposter higher chances of being accepted in future authentication attempts.
Also, due to the way the authors described this prevention mechanism, it can be assumed that their system favors trials resulting in a match over those who do not.
This is not properly addressed in the article, but \autoref{fig:messerman-threshold} supports this assumption, as a higher number of trials negatively affects FMR and positively affects FNMR.

\subsection{Scalability}
As similarly discussed in \autoref{sec:gnp-scalability}, this system also has a reliance on other users in the application, though only a subset of the total userbase.
The addition of a threshold does however lower this reliance slightly, as it enables the system to perform better with very small userbases and also to function with only one single user.

On the issue of computation speed, the half second response time is more suitable for my master thesis than the 140 seconds in \cite{gnp}.
Even so, this does not necessarily mean that I can use this PA system as a whole, as there are a number of problems to be discussed.

\subsection{Enrollment}
Due to how the authors conducted their experiments, the reported performance is subject to discussion.
Only 3500 keystrokes were needed to build a user profile ready to be used for authentication, which is very efficient both for the length of the enrolment process, as well as for scalability in terms of storage.
Compared to Gunetti and Picardi's user profiles based on $14*800\approx{11200}$ keystrokes \cite{gnp}, a minimum of 3500 is a better fit for an online e-mail application.
The low block size of 50--150 also greatly limits the damage potential for imposters.
If this PA system were to be used for securing an entire operating system though, such as the setting in my master thesis, the experiments in both research articles \cite{gnp, Messerman} are unsatisfactory in captured variance of behavior.
Messerman et al.'s \cite{Messerman} experiments probably captured higher variance, as there was no restriction to language used, and the volunteers were not suggested to write about any certain topics.
As the keystrokes were recorded in the background, the participants were not merely typing text in order to produce samples; they were simply composing e-mails that they otherwise would have written regardless of participating in the experiment.
Still, restricting to only e-mails means other behavior such as gaming and coding was not recorded. 
It is not known how this system would perform in such scenarios with only 3500 keystrokes being covered.

\subsection{Performance evaluation issues}
When evaluating the performance of the PA system, the authors used various settings and parameters, as already mentioned in \autoref{sec:messerman-experimental}.
When evaluating different performance metrics, they included specific settings in footnotes.
Examples of this are the experiments for investigating how the performance was affected by the total number of users in the userbase as well as the number of users considered in the decision process.
In both of these cases, they used 17 external imposters and 23 internal imposters/legitimate users.
This is a total of 40 users, which fits the number of users producing over 3500 keystrokes: $55-15=40$.
Apart from this, they also showed the settings for investigating the maximum distance threshold's impact on error rates, which is the experiment shown in \autoref{fig:messerman-threshold}.
Here they used 20 external imposters and 30 internal imposters/legitimate users.
As this puts the total involved users as 50, they seem to contradict their own minimum number of keystrokes in the enrollment process.
The true performance results are therefore not completely clear, as they do not explain this contradiction in their article.

Another issue regarding their performance evaluation is the fact that the results in \autoref{tab:messerman-perf} are achieved with a maximum distance threshold of 0.57.
Again, the authors do not explain the reasoning for this specific value.
This leads me to believe that the results are influenced by overfitting, as 0.57 happens to be an optimal threshold as seen in \autoref{fig:messerman-threshold}, especially regarding external FMR for 1 trial, which shows a valley at that threshold.
If the authors indeed overfitted their experiment to their dataset, it is difficult to imagine the true performance of the PA system employed in practice.

Lastly, I would like to mention two unclear issues, with the first being the lack of clarity regarding which n-graphs were considered in the experiments.
They do mention that they found an average of 32 shared digraphs between attempt samples of 50 keystrokes and stored samples of 700 keystrokes, however they do not tie this up to the performance evaluations.
Secondly, they do not explain why they only use the R-measure, as opposed to combining it with an A-measure as Gunetti and Picardi did \cite{gnp}.
Seeing performance results for a combined R and A distance would be interesting, both for the effects on error rates and computation speed.

\chapter{Ferreira and Santos}
Another PA system based on Gunetti and Picardi's work was published by Ferreira and Santos in 2012 \cite{superResults}.
They use a block size of 250 keystrokes and also periodically update the user profile after three successfully authenticated attempts, in other words by merging the attempts into a sample of 750 keystrokes to be integrated into the user profile.
While they state that one such sample technically is enough to start the authentication stage, the accuracy would obviously be negatively affected by having such a small user profile.
The user profile contains 15 such samples, and during authentication these are \textbf{merged} to one template based on $15*750 = 11250$ keystrokes to be compared to the 250 keystroke attempt sample. 
As new 750 keystroke samples are submitted, the oldest ones in the user profile are replaced by the new samples, not unlike the adaptive user model in Messerman et al.'s PA system \cite{Messerman}.
An important difference between the two systems is that while Messerman et al. only uses the R measure, Ferreira and Santos' system utilizes both R and A measures for distance calculations.
%As opposed to the PA system proposed by Messerman et al. \cite{Messerman} which was discussed in \autoref{chap:messerman}, Ferreira and Santos' system uses both R and A measures for their distance calculations.

They refer to a previous study \cite{superOld}, where they along with a third author describe their own method for calculating A measures.
As shown in \autoref{sec:gnp-algorithm}, Gunetti and Picardi used a threshold of 1.25 in the calculation of A measures to determine whether n-graphs from the probe and reference were similar.
Ferreira and Santos' method takes advantage of standard deviations, as every n-graph of a \textit{subtemplate} has an associated average, standard deviation and number of occurrences.
Subtemplates (called subsamples in original paper) are separated collections of \textbf{dwell times} for single keys, \textbf{flight times} for digraphs and \textbf{durations} for di-, tri- and fourgraphs extracted from a sample.

An example of a subtemplate would be all trigraph durations extracted from a sample.
Then, every trigraph in the subtemplate would have a standard deviation, average duration and number of occurrences within the subtemplate.
Using these values, they calculate the 10\% most consistent n-graphs in every subtemplate, and store a record of them in the user profile.
During comparisons, they apply a lower similarity threshold when comparing n-graphs that are among the 10\% most consistent.
This enables them to place more strict expectations where the genuine user rarely deviates from their usual typing patterns.
They mention that they by default use a similarity threshold of 1.10 for consistent n-graphs and 1.25 for others, and that these are adjusted based on every individual user's timing consistency \cite{superOld}.
Unfortunately, they do not describe exactly how this adjustment is performed.

Taking consistent n-graphs into account, the rest of the A measure is calculated as described in \autoref{chap:gnp}. The R measure is also calculated in the same manner as the original method, and the A and R measure are combined into what they call the \textit{global} distance.
While a probe is compared to several other users in \cite{gnp, Messerman}, Ferraira and Santos' PA system bases its decisions solely on a global distance threshold.
Interestingly, the global distance threshold is calculated individually for every user.
This is done computing the global distance between every 750 keystroke sample in the database and the merged references , not including their own occurrences.
This can alternatively be viewed as every sample being compared to the 14 other samples.
The average distance of all of these calculations give an expectation of how the genuine user should be performing compared to their own profile.
The global distance threshold is then set to this average distance minus a static degree of tolerance in order to allow for some variations.
This threshold largely affects the error rates, and can be changed to balance FMR and FNMR according to how strict of a system is wanted.
This is further shown in \autoref{sec:ferreira-experiment}.

Another interesting feature that the authors proposed is to asynchronously authenticate the user when certain events happen.
One example could be after a longer period of silence where the genuine user may have left the workstation, an authentication could be triggered after 75 keystrokes.
Then, a sample consisting of the last $175 + 75 = 250$ keystrokes would be tested, in order to potentially catch any imposter who would have taken control of the computer.
Attempting to save or overwrite important files could also trigger this functionality.

\section{Experimental setting}
\label{sec:ferreira-experiment}
60 participants installed a logging software on their computers which captured their keystroke data in the background, never interfering with their daily activities.
The data collection period lasted for two weeks and 15 samples were collected to build user profiles in addition to another 15 samples which were to be used for testing.
These extra samples were used both to simulate genuine access attempts and as imposter attempts, resulting in a total of 900 genuine attempts and 53100 imposter attempts \cite{superResults}.


\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{ferreira/distr}
    \caption{Distribution of scores for genuine and imposter attempts against all user profiles as presented in \cite{superResults}.}
    \label{fig:ferreira-distr}
\end{figure}

The results of the simulations showed an equal error rate of 1.4\%, and they point out a specific setting for the degree of tolerance mentioned earlier which gives a 0.5\% FMR and 2.7\% FNMR.
This translates to an ANIA of $250 / (1-0.005) \approx{251}$, and ANGA of $250 / 0.055 \approx{4545}$, which will be discussed in \autoref{sec:ferreira-discussion}.
They also found that there was a clear distinction between genuine and imposter attempts, as seen in \autoref{fig:ferreira-distr}.
Note that I have intentionally been referring to their matching "score" as a distance measure in order to more easily show their system's relation to the other PA systems using R and A measures. 
Distances and match scores generally work in the same way, and a distribution of distances would have the red and green dots in \autoref{fig:ferreira-distr} swap places.
While some of the users generally have lower scores to their own profiles, the imposters score even worse, indicating that having custom distance thresholds for every user benefits the performance of the overall system.
I would like to mention that it is unclear why the figure involves 65 users instead of 60.

The authors also created a prototype of the PA system for testing it in real time, though at a smaller scale than the simulations.
Ten participants each produced a fixed-text stored sample of 200 keystrokes, and testing was conducted by having one genuine attempt and a random person acting as an impostor. This was done in 200 iterations, and resulted in a 0.5\% FMR and a 5.5\% FNMR, which shows that the smaller sample size negatively affected the FNMR, and thus also affected the ANGA which in this case was 3636.

\section{Discussion}
\label{sec:ferreira-discussion}
Ferreira and Santos' PA system seems particularly fitting for my master thesis, as its intention to be used for protecting an entire workstation by observing keyboard input in all applications and contexts is similar to that of Mondal's CA system which I will be extending \cite{mondal}.
The experiment's uncontrolled data collection phase also matches Mondal's experiment quite well, which makes comparing the systems more sensible.
As I will be using Mondal's database for my own project, I am likely to receive similar results when applying Ferreira and Santos' methods to it, as the data should have similar amounts of variation in typing behavior per user.

While their method for asynchronous authentication is a great measure for possibly detecting imposters even earlier than the block size originally allows, and even on special triggers, this is mostly relevant for actual real-time implementations of the software.
My master thesis will revolve around simulations and analysis, and I could therefore omit this functionality if I were to integrate this PA system into the CA system.
The CA system already tries to detect imposters as early as possible, and for that reason partly covers the intended motivation for the proposed asynchronous authentication.

\subsection{Classification}
A great feature of the PA system is its sole reliance on a user-fitted global distance threshold.
Not only does this ensure that users who tend to score poorly against their own user profile still can use the PA system with satisfying performance, but it also lets the system avoid involving other users in the classification process.
As the PA system operates application-wide, one can imagine a scenario where college campus computers would install the PA system.
Such computers are accessible by thousands of students, and comparing the typing patterns of one user to every other registered student such as Gunetti and Picardi's original system would do \cite{gnp} is clearly not practical.
While Messerman et al. \cite{Messerman} would not show the same scalability issues due to only including a subset of all students, Ferreira and Santos' system inherently avoids the potential problem of having a genuine user falsely rejected due to their probe haphazardly being more similar to another student's behavior than that of their own.

While not involving other users positively affects the scalability of the PA system, the rather large user profiles consisting of over 11000 keystrokes could pose a challenge in real-time applications if they have a very large amount of users.
This could probably be reduced if necessary, though the performance impact would have to be analyzed extensively beforehand.
Regardless, as I will not make a real-time application this is not an issue in my specific case.
Another feature that could be problematic for a real-time implementation is periodically updating the user profile, as it would corrupt the user database if imposters were falsely accepted.
However, three consecutive attempts would have to be accepted in Ferraira and Santos' system, which lowers this risk.
If an imposter were accepted three times in a row, the user profile would have to be retroactively rolled back to a valid state.
Again, this is another feature that can be omitted from the simulations in my master thesis.

\subsection{Performance}
Seen in relation to the short block size and high variance datasets, achieving an EER of 1,4\% is remarkable.
An imposter's window of opportunity is considerably smaller with a block size of 250 keystrokes, compared to Gunetti and Picardi's 800 block size.
A block size this small is also very suitable for integration with the CA system, as the CA's ANIA rating is around 500 \cite{mondal} at its best settings.
This means that the PA system could positively affect the ANIA rating, as periodic authentications would occur every 250 keystrokes.

As the static (system specific) degree of tolerance can be changed to influence the relationship between the FMR and FNMR, this allows for tailoring the level of strictness of the PA to better match that of the CA.
However, I would have to be aware of the possibility of overfitting the degree of tolerance to Mondal's dataset.
A preventive measure could be to select a random subset of the users and adjusting the degree of tolerance to fit the subset, and using that degree of tolerance for the entire dataset, similarly to the method described in \autoref{chap:gnp}.

Regarding the performance results from the \textit{prototype} experiment, it does give some indication that the system could work in real life, though as the context was highly controlled with static text and relatively few participants, not too much emphasis can be put those results compared to those of the main experiment.


%Positive: Gives ROC curve. Prevents us from only seeing overfitted performance evaulations.


%Negative: Doesn't mention computation time. Though, it should not be high at all, as probes are only compared to genuine user profile.
\subsection{Follow-up study}
A follow up study was performed by Santos and two other authors where they investigated ways to lower the sample size and positively affect the performance of the PA system \cite{Pinto2014}.
Using different weights for different types of features (dwell, flight, digraph, trigraph, fourgraph) and different weights for A and R measures, they were able to reduce the size of attempt samples to 150 keystrokes, with an FMR and FNMR of around 2\%.
They found that dwell times, flight times and digraphs were the most effective features to be used for authentication.
However, the experiments were performed with only 10 participants, and generally lacks clarity, especially so regarding the performance.
I will therefore not discuss this paper in detail.


\chapter{Ahmed and Traore}
The PA system previously discussed in dedicated chapters have all applied a statistical approach for their authentication schemes.
Machine learning is another approach that has gained popularity in recent years, and Ahmed and Traore \cite{Ahmed}'s proposed PA system is based on this approach.
One of their goals was to decrease the needed amount of keystroke data from enrollment.
PA systems which rely on an uncontrolled free-text enrollment phase will, depending on the amount of data collected, have varying amounts of different n-graphs recorded and stored.
Therefore, a user may generate an attempt sample containing one or more n-graphs not present in the reference.
For this reason, the authors proposed a method called \textit{sorted time mapping} for predicting what timing features a missing n-graph would have, based on relations between the n-graphs present in the reference.

Their system relies on covering the most frequently used \textit{monographs}.
The definition of "frequent" in this context is flexible, as it means the set of keys with a higher chance of occurrence than a certain probability threshold.
In this case, "chance of occurrence" means the chance of a key being \textit{the next key to be pressed}, not the chance of it occurring once in an entire enrollment sample.
The size of the enrollment sample must then be decided so that all monographs above the probability threshold is covered.
For instance, if the probability threshold is set to 0.001, all keys with higher chance of occurrence than 0.1\% must be covered in the enrollment sample, and the size of the enrollment sample must be set to a value that satisfies this criteria.
More on how this size is determined is described in \autoref{sec:ahmed-experimental}.

\section{Neural networks}
Two feed forward neural networks of type multilayer perceptron (MLP) are trained during using the enrollment sample and used for behavior modeling.
One network processes monographs, while the other processes digraphs.
For training the digraph network, a \textit{digraph mapping table} must be generated based on the data from the enrollment sample.
This table contains an entry for the keycode of every key in the enrollment sample.
These entries are sorted by the average flight time \underline{to} the monographs, based on all recorded digraphs with that monograph as the second key.
Every key then has an \textit{digraph key order (DKO)}, which represents the average flight time to that key relative to all other keys. 
The actual average flight times are excluded from the table; only the DKO of each key is included.
Similarly, a \textit{monograph mapping table} is needed for training the monograph network. 
This table is ordered by dwell times instead of flight times, giving each key from enrollment a \textit{monograph key order}.

The digraph network is trained with all digraphs from the enrollment sample encoded as DKOs.
As seen in \autoref{fig:ahmed-networks} (b), it is trained with two inputs, namely "from" and "to", which are fed the DKO of the two keys involved in a digraph. 
The training output is the actual flight time of the digraph.
Training the monograph network is done similarly, though with MKOs as input and actual dwell times as output.
Both networks are trained using the Levenberg–Marquardt algorithm.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{ahmed/networks}
    \caption{The structure of the monograph network (a) and digraph network (b), as presented in \cite{Ahmed}.}
    \label{fig:ahmed-networks}
\end{figure}

When the networks are trained, their weights are stored along with the monograph and digraph mapping tables as a \textit{reference signature}.
The reference signature is loaded during the authentication phase, as all users of the PA system utilize the same two neural networks, only with their own mapping tables and network weights.
\autoref{fig:ahmed-authentication} shows how data is processed during periodic authentication.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.75\textwidth]{ahmed/authentication}
    \caption{Ahmed and Traore's periodic authentication mechanism \cite{Ahmed}.}
    \label{fig:ahmed-authentication}
\end{figure}
When an attempt sample is collected, monograph dwell times and digraph flight times are extracted from the raw data, essentially acting as probes.
Recorded monographs are mapped into MKOs using the genuine user's monograph mapping table.
The MKOs are then fed as input to the monograph network which is loaded with the genuine user's weights.
The output dwell times represent the expected values which are compared to the dwell times from the attempt samples, with each comparison resulting in a deviation.
When all dwell time deviations are fed to the decision module, it calculates the average absolute deviation (AAD), using the following equation \cite{Ahmed}:
\begin{equation}
AAD\textsubscript{mono}={{\sum\limits_{i=1}^{N_{\rm mono}}{{{\left\vert{d_{i}-D_{i}}\right\vert}\over{D_{i}}}\times100}}\over{N_{\rm mono}}}
\end{equation}
with N\textsubscript{mono} being the total number of monographs from the probe, d\textsubscript{i} being the \textit{i}th probe monograph's dwell time and D\textsubscript{i} being the \textsubscript{i}th monographs's expected dwell time.
The expected dwell time is the output of the monograph network.

Digraphs are processed similarly, as seen in \autoref{fig:ahmed-authentication}, though the digraph network outputs an estimated flight time if the current digraph being processed was not included in the training.
It calculates this estimated flight time by viewing the digraphs relation to the other digraphs based on the DKOs from the digraph mapping table.
The actual flight time of the probe digraph is compared to the output of the digraph network, regardless if the digraph was missing from enrollment or not.

When the AADs for mono- and digraphs are calculated, the decision module combines them linearly using weights.
The combined deviation is calculated using the following equation:
\begin{equation}
D = B * AAD\textsubscript{mono} + (1-B)AAD\textsubscript{di}
\end{equation}
where D is the combined deviation and B is a balancing factor (originally called dependability factor).
The balancing factor is a value between 0 and 1, and lower values place more weight on the digraph AAD.
The final output is true or false, depending on the combined deviation and a selected decision threshold.
A combined deviation below the the threshold leads to the output being true, meaning the probe behavior is recognized as the genuine user.

\section{Experimental setting}
\label{sec:ahmed-experimental}
Their main experiment consisted of a completely uncontrolled collection phase, with 53 participants installing a keystroke logging tool on their personal computers.
They had a high variation in typing skills, age and gender, and around 18 000 keystrokes were collected from every user on average over the course of five months.

As mentioned earlier, the size to be used for enrollment samples must cover the most frequently used keys.
During the experiment, the authors investigated how many keystrokes were needed for a probability threshold of 0.001, which corresponded to the 60 most frequently used keys \cite{Ahmed}.
They found that 1350 keystrokes were needed to cover 100\% of the most frequently used keys for three arbitrary participants, and decided that 1500 keystrokes would be used as an enrollment sample size for the rest of the experiment.

The first 1500 keystrokes from the exeriment's collection phase were used to build the user profile, consisting of mono- and digraph mapping tables, along with networks with user specific weights.
The rest of the keystrokes collected were divided into attempt samples of length 500, each being used as a genuine test sample and for attacking all other users.
They call this a leave-one-out cross-validation test (LOOCV), though it seems to me that this is not the case as they specifically state that the user profiles were built using the \underline{first 1500} keystrokes \cite{Ahmed}.
This means that all test sets are tested against the same training set, which can not be called cross-validation.
Regardless, the test was repeated for all 53 participants.

\subsection{Performance}
\label{sec:ahmed-performance}


\section{Discussion}
%Resembles R measure

%Though 500 block length is rather lengthy, it might still positively affect the results of CA, since its ANIA is ~500 and above. That's just an average anyway. Std dvt?


%Can possibly use the digraph approx. method along with another system?

%Positive: Completely unrestricted enrolllment, suitable for master project.
%Positive: high variation in collection. Very old computers though (probably old dataset), but that doesnt necessarily mean anything.
%Positive: Only relies on genuine user data, doesn't need to be trained with imposter data.

%Negative: They claim "far lower processing time" than 
%Negative: Must be retrained
%Negative: 70% in fig 10 has wrong FAR? Really would like to see that performance. Also, their stated performance of 0.0152% FAR and 4.85 % FNMR doesn't exist in the figure. Probably several errors here.
%Negative: Super inconsistent sample size?? based on their reference to GNP's sample size, I can ASSUME "digraphs" means keystrokes.
%Negative: While it uses a small selected enrollment sample, way more data is in reality needed to decide how small of a sample can actually be used. Of course, they have a large sample size, so that their findings can probably be used in other settings, but if another probability threshold is to be used, determining the needed sample size is difficult.

% http://onlinelibrary.wiley.com/doi/10.1002/cpe.3718/full WRITE ABOUT THIS AFTER AHMED



% http://ieeexplore.ieee.org/document/7529146/ this one seems pretty good (state?)
%NOTE: SLIDING? \cite{sliding}. Probably worth writing about (incl. in state)
%NOTE: VILLANI MAY BE WORTH INCLUDING BECAUSE OF EUCLIDIAN DISTANCE (incl. state)
% https://www.hindawi.com/journals/tswj/2013/408280/talks about machine learning
\chapter{Concluding discussion}
% NOTE: Mention possibility of sliding window?


%NOTE: FIX BIB STYLE
\bibliographystyle{plain}
%\bibliographystyle{gucmasterthesis}
\bibliography{bib}



\end{document}





%IEEE computer society keywords
%http://www.computer.org/portal/site/ieeecs/menuitem.c5efb9b8ade9096b8a9ca0108bcd45f3/index.jsp?&pName=ieeecs_level1&path=ieeecs/publications/author/keywords&file=ACMtaxonomy.xml&xsl=generic.xsl&
